{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Finish <a href=\"https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU\">Stanford</a>\n",
    "2. Finish <a href=\"https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B\">3brown1blue Linear Algebra</a>\n",
    "\n",
    "# Stanford CS229 Lecture #1:\n",
    "\n",
    "## What is machine learning? \n",
    "\n",
    "Arthur Samuel(1959) Machine Learning in checkers game! \n",
    "\n",
    "Machien Learning requires narrow task.\n",
    "\n",
    "Tom Mitchell (1998) \n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "Example:\n",
    "\n",
    "Database of housing prices:\n",
    "\n",
    "    x(area), y(price)\n",
    "\n",
    "y1 = 1250 square feet;\n",
    "\n",
    "You could just draw straight line through the graph\n",
    "\n",
    "This is a **regression problem**\n",
    "\n",
    "Another example:\n",
    "\n",
    "Healthcare problem\n",
    "\n",
    "Decide if tumor is malign or belign or cancerous\n",
    "\n",
    "    x(tumore_size), y(malign)\n",
    "\n",
    "malign is represented as 0 or 1\n",
    "\n",
    ".75 size \n",
    "\n",
    "Find out if the tumor is malignent\n",
    "\n",
    "This is a **classification problem** \n",
    "\n",
    "In the real world: \n",
    "\n",
    "X will be multi-dimensianol, consisting of multiple **features**\n",
    "\n",
    "In the healthcare problem \n",
    "\n",
    "the X could be represented consisting of two features: tumor_size, age_of_patient (two dimension vector)\n",
    "\n",
    "There could be infinite features? Infinite dimensional vector? How will the computer store the data?\n",
    "\n",
    "There is a method called **Kernel**\n",
    "\n",
    "That was supervised learning is same as teach the AI how to do stuff, teacher being the human \n",
    "\n",
    "### ML strategy\n",
    "\n",
    "Systematic engineering discipline?\n",
    "\n",
    "Making you model work is a like dark magic? \n",
    "\n",
    "Evolve from dark magic to systematic engineering discipline...\n",
    "\n",
    "*A tip if you want to run your code faster, you should run profiler to see where the code is bottlenecking*\n",
    "\n",
    "Sum up: \n",
    "\n",
    "1. First subject: Machine Learning \n",
    "2. Second subject: Leaning Theory\n",
    "3. Third subject: Deep Learning\n",
    "4. Fourth subject: Neural Learning\n",
    "5. Fifth subject: Unsupervised Learning\n",
    "\n",
    "Deep Learning is developing very rapidly\n",
    "\n",
    "Clustering? Genetic data? Clustering algorithm organizing computers? Clustering social app's friends and groups? \n",
    "\n",
    "Cocktail party ML problem.\n",
    "\n",
    "Say there is multiple people speaking. How to seperate their voices? Can the algorithm seperate the voices? \n",
    "\n",
    "## Unsupervised Learning?\n",
    "\n",
    "Tokyo -> Japan\n",
    "Washington DC -> US \n",
    "\n",
    "the data is related but its not labeled... \n",
    "\n",
    "## Reinforcement Learning?\n",
    "\n",
    "No one knows how to fly helicopter optimally. Its similar to training dogs. If the dog does a good thing, he gets a treat but if he does bad things we say he is a bad dog. Simple enough. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2 \n",
    "\n",
    "Linear regression Supervised Learning \n",
    "\n",
    "We would have training set to feed the algorithm.\n",
    "The algorithm should output a function with a hypothesis.\n",
    "\n",
    "And then after that if we feed the function a new unseen data it should predict.\n",
    "\n",
    "How to represent the hypothesis?\n",
    "    h(x) => O(0) + O(1)x \n",
    "\n",
    "if you have more data such as bedrooms\n",
    "\n",
    "<img src=\"./images/house-data.png\" height=\"220px\"/>\n",
    "\n",
    "the function would change to this \n",
    "\n",
    "    x(1) = size\n",
    "    x(2) = #bedrooms\n",
    "\n",
    "    h(x) => O(0) + O(1)x(1) + O(2)x(2)\n",
    "\n",
    "** New notations **\n",
    "\n",
    "<img src=\"./images/new-notation.png\" height=\"200px\">\n",
    "\n",
    "*Theta*\n",
    "\n",
    "Theta is the parameters of learning algorithm. \n",
    "m = # training examples\n",
    "    (# rows in table of above)\n",
    "\n",
    "x = \"inputs\" / features\n",
    "y = \"output\" / target variable / label\n",
    "\n",
    "    (x, y) = training example\n",
    "    (x(i), y(i)) = i'th training example\n",
    "\n",
    "n = number of features, in this example we would have 2 features \n",
    "\n",
    "<img src=\"./images/n-n-2.png\" height=\"200px\">\n",
    "\n",
    "*Feature*\n",
    "\n",
    "x(0) being always 1, x(1) size of the house, x(2) number of bedrooms\n",
    "\n",
    "<img src=\"./images/n-n-3.png\" height=\"200px\">\n",
    "\n",
    " How do you choose parameters of theta?\n",
    "\n",
    " Choose theta such that h(x) ~ y for training example\n",
    "\n",
    " h(theta)(x) = h(x) # is the same thing \n",
    "\n",
    " *Cost function J of theta*\n",
    "\n",
    "<img src=\"./images/cost-function.png\" height=\"200px\">\n",
    "\n",
    "*Gradient Descent*\n",
    "\n",
    "Start with some value of theta (say theta = vector of 0)\n",
    "\n",
    "keep changing theta to reduce J(theta)\n",
    "\n",
    "What is this?\n",
    "\n",
    "*Gradient Descent*\n",
    "\n",
    "<img src=\"./images/gradient-descent.png\" height=\"200px\">\n",
    "\n",
    "Gradient Descent is saying lets say that I start from a random location and is wondering in which direction I should take step to go down hill as quickly as possible.\n",
    "\n",
    "There are many possibilities one which the function stepping into the less optimal downhill and could be stuck there and that would be not the local optimum.\n",
    "\n",
    "<img src=\"./images/grad-desc-2.png\" height=\"200px\"> \n",
    "\n",
    "Gradient Descent Algorithm - in this example the training set is fixed, the cost function J is a fixed function there's function of parameters Theta.\n",
    "\n",
    "<img src=\"./images/theta.png\" height=\"200px\"> \n",
    "\n",
    "(:= # assignment)\n",
    "\n",
    "a(alpha) - learning rate\n",
    "\n",
    "<img src=\"./images/direvative-1.png\" height=\"200px\"> \n",
    "\n",
    "after the calculations it ends up being \"(h(theta)(x) - y) * x(j)\"\n",
    " \n",
    "Theta J is being updated according to this formula\n",
    "\n",
    "theta(j) := theta(j) - a(learning rate) * (h(x) - y) * x(j)\n",
    "\n",
    "This was for single training example but you have actually have M training example, so the correct form is this.\n",
    "\n",
    "<img src=\"./images/correct-form.png\" height=\"200px\"> \n",
    "\n",
    "<img src=\"./images/correct-form-2.png\" height=\"200px\"> \n",
    "\n",
    "Gradient Descendent Algorithm\n",
    "\n",
    "Repeat until convergence, carry out this update, and in each iteration of gradient descent, you dod this update (for j = 0, 1, ..., n)\n",
    "\n",
    "n # number of features\n",
    "\n",
    "*j of theta*\n",
    "\n",
    "<img src=\"./images/j-of-theta.png\" height=\"200px\"> \n",
    "\n",
    "Default theta degree of zero\n",
    "\n",
    "it turns out that the direction of steepest descent is always at 90 degrees, is always orthogonal to the contour direction. \n",
    "\n",
    "<img src=\"./images/theta-function-graph.png\" height=\"200px\"> \n",
    "\n",
    "I was not able to understand anything because of its notations and other explanations. So I searched for Gradient Descent on YouTube and found this. \n",
    "\n",
    "<img src=\"./images/simple_explanation.PNG\" height=\"200px\"> \n",
    "\n",
    "If you make the learning rate to big it might overstep the minimum but if you set it to small then the algorithm would slower. So we would try out different numbers for learning rate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
